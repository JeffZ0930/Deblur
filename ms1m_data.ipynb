{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pick one female and male in the MS1M Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('10760', 602), ('9828', 598), ('8884', 586), ('10893', 556), ('9775', 556)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs_count = {}\n",
    "\n",
    "data_path = \"C:/Users/Asus/Desktop/DL_research/Data-Preparation/data/faces_emore/imgs\"\n",
    "\n",
    "count = 0\n",
    "\n",
    "for folder in os.listdir(data_path):\n",
    "    # if count >= 1000:\n",
    "    #     break\n",
    "    # count += 1\n",
    "\n",
    "    imgs_path = os.path.join(data_path, folder)\n",
    "    imgs_count[folder] = len(os.listdir(imgs_path))\n",
    "    \n",
    "\n",
    "sorted_folder_file_counts = sorted(imgs_count.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "top_5_folders = sorted_folder_file_counts[:5]\n",
    "\n",
    "# top_5_folders [('10760', 602), ('9828', 598), ('8884', 586), ('10893', 556), ('9775', 556)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Gaussian Blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Female '8884'\n",
    "# Male '10893' \n",
    "\n",
    "female_original = \"C:/Users/Asus/Desktop/DL_research/Data-Preparation/data/faces_emore/imgs/8884/\"\n",
    "male_original = \"C:/Users/Asus/Desktop/DL_research/Data-Preparation/data/faces_emore/imgs/10893/\"\n",
    "\n",
    "output_folder = \"C:/Users/Asus/Desktop/DL_research/Data-Preparation/data/blur/\"\n",
    "\n",
    "\n",
    "level_1 = 7\n",
    "level_2 = 13\n",
    "level_3 = 25\n",
    "\n",
    "# Female\n",
    "\n",
    "for img_name in os.listdir(female_original):\n",
    "    img_path = os.path.join(female_original, img_name)\n",
    "    img = cv2.imread(img_path)\n",
    "\n",
    "    blurred_1 = cv2.GaussianBlur(img, (level_1, level_1), 0)\n",
    "    output_path = os.path.join(output_folder, \"level_1/female\", img_name)\n",
    "    cv2.imwrite(output_path, blurred_1)\n",
    "\n",
    "    blurred_2 = cv2.GaussianBlur(img, (level_2, level_2), 0)\n",
    "    output_path = os.path.join(output_folder, \"level_2/female\", img_name)\n",
    "    cv2.imwrite(output_path, blurred_2)\n",
    "\n",
    "    blurred_3 = cv2.GaussianBlur(img, (level_3, level_3), 0)\n",
    "    output_path = os.path.join(output_folder, \"level_3/female\", img_name)\n",
    "    cv2.imwrite(output_path, blurred_3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "# img = cv2.imread(\"data/faces_emore/imgs/8884/617685.jpg\")\n",
    "# blurred_7x7 = cv2.GaussianBlur(img, (7, 7), 0)\n",
    "# cv2.imshow(\"7x7\", blurred_7x7)\n",
    "# cv2.waitKey(0)\n",
    "\n",
    "# blurred_25x25 = cv2.GaussianBlur(img, (13, 13), 0)\n",
    "# cv2.imshow(\"25x25\", blurred_25x25)\n",
    "# cv2.waitKey(0)\n",
    "\n",
    "# blurred_50x50 = cv2.GaussianBlur(img, (25, 25), 0)\n",
    "# cv2.imshow(\"50x50\", blurred_50x50)\n",
    "# cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare dataset for pix2pix GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_transforms = transforms.Compose([\n",
    "    # transforms.RandomResizedCrop(224),\n",
    "    # transforms.RandomHorizontalFlip(0.1),\n",
    "    # transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    # transforms.RandomRotation(20),\n",
    "    # transforms.RandomVerticalFlip(0.1),\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Assuming ImageNet mean and std\n",
    "])\n",
    "\n",
    "dataset = ImageFolder(root='C:/Users/Asus/Desktop/DL_research/Data-Preparation/data/clear/female', transform=clear_transforms)\n",
    "\n",
    "train_size = int(0.7 * len(dataset))  # 70% for training\n",
    "val_size = int(0.15 * len(dataset))   # 15% for validation\n",
    "test_size = len(dataset) - train_size - val_size  # Remaining for testing\n",
    "\n",
    "level = 3\n",
    "\n",
    "train_dir = \"C:/Users/Asus/Desktop/DL_research/pytorch-CycleGAN-and-pix2pix/datasets/deblur/level_\" + str(level) + \"/clear/train\"\n",
    "val_dir = \"C:/Users/Asus/Desktop/DL_research/pytorch-CycleGAN-and-pix2pix/datasets/deblur/level_\" + str(level) + \"/clear/val\"\n",
    "test_dir = \"C:/Users/Asus/Desktop/DL_research/pytorch-CycleGAN-and-pix2pix/datasets/deblur/level_\" + str(level) + \"/clear/test\"\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "for dataset, output_folder in [(train_dataset, train_dir), (val_dataset, val_dir), (test_dataset, test_dir)]:\n",
    "    for idx in range(len(dataset)):\n",
    "        image, _ = dataset[idx]\n",
    "        output_path = os.path.join(output_folder, f\"{idx}.jpg\")\n",
    "        save_image(image, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_path = \"C:/Users/Asus/Desktop/DL_research/pytorch-CycleGAN-and-pix2pix/datasets/deblur/level_\" + str(level) + \"/clear/\"\n",
    "blur_path = \"C:/Users/Asus/Desktop/DL_research/pytorch-CycleGAN-and-pix2pix/datasets/deblur/level_\" + str(level) + \"/blurred/\"\n",
    "\n",
    "kernel_size = 25\n",
    "\n",
    "for folder in os.listdir(clear_path):\n",
    "    folder_path = os.path.join(clear_path, folder)\n",
    "\n",
    "    for img_name in os.listdir(folder_path):\n",
    "        img_path = os.path.join(folder_path, img_name)\n",
    "\n",
    "        img = cv2.imread(img_path)\n",
    "        blurred = cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n",
    "        output_path = os.path.join(blur_path, folder, img_name)\n",
    "        cv2.imwrite(output_path, blurred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Two Persons (One male & one female)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "dataset = ImageFolder(root='C:/Users/Asus/Desktop/DL_research/Data-Preparation/data/clear/female', transform=clear_transforms)\n",
    "\n",
    "train_size = int(0.7 * len(dataset))  # 70% for training\n",
    "val_size = int(0.15 * len(dataset))   # 15% for validation\n",
    "test_size = len(dataset) - train_size - val_size  # Remaining for testing\n",
    "\n",
    "level = 3\n",
    "\n",
    "train_dir = \"C:/Users/Asus/Desktop/DL_research/pytorch-CycleGAN-and-pix2pix/datasets/deblur/level_\" + str(level) + \"/clear/train\"\n",
    "val_dir = \"C:/Users/Asus/Desktop/DL_research/pytorch-CycleGAN-and-pix2pix/datasets/deblur/level_\" + str(level) + \"/clear/val\"\n",
    "test_dir = \"C:/Users/Asus/Desktop/DL_research/pytorch-CycleGAN-and-pix2pix/datasets/deblur/level_\" + str(level) + \"/clear/test\"\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "for dataset, output_folder in [(train_dataset, train_dir), (val_dataset, val_dir), (test_dataset, test_dir)]:\n",
    "    for idx in range(len(dataset)):\n",
    "        image, _ = dataset[idx]\n",
    "        output_path = os.path.join(output_folder, f\"{idx}.jpg\")\n",
    "        save_image(image, output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
